{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNpPkysYL7D-"
      },
      "outputs": [],
      "source": [
        "# Airbnb Listing Price Analysis Project"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 0) Install & import libraries\n",
        "!pip install -q xgboost scikit-plot\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import files\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import xgboost as xgb\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "FTVWlU1eMxfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Upload dataset\n",
        "print(\"Upload your Airbnb listings CSV (e.g., AB_NYC_2019.csv or equivalent)\")\n",
        "uploaded = files.upload()\n",
        "if len(uploaded) == 0:\n",
        "    raise SystemExit(\"No file uploaded.\")\n",
        "fname = list(uploaded.keys())[0]\n",
        "df = pd.read_csv(fname)\n",
        "print(\"Shape:\", df.shape)\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "KaQFBxP5M_Pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Inspect & clean basic things\n",
        "# Show info & missing values\n",
        "print(df.info())\n",
        "print(df.isnull().sum().sort_values(ascending=False).head(20))\n",
        "\n",
        "# If price stored as string with $ or commas, clean it\n",
        "if 'price' in df.columns:\n",
        "    def clean_price(x):\n",
        "        if pd.isna(x): return x\n",
        "        if isinstance(x, str):\n",
        "            return float(x.replace(\"$\",\"\").replace(\",\",\"\").strip())\n",
        "        return float(x)\n",
        "    df['price'] = df['price'].apply(clean_price)\n"
      ],
      "metadata": {
        "id": "n-eeFu2NWcd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) Exploratory Data Analysis (EDA)\n",
        "\n",
        "# Histogram of price\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.histplot(df['price'].dropna(), bins=60, kde=True)\n",
        "plt.title(\"Distribution of Prices\")\n",
        "plt.xlim(0, df['price'].quantile(0.95))\n",
        "plt.show()\n",
        "\n",
        "# Price vs room_type\n",
        "if 'room_type' in df.columns:\n",
        "    plt.figure(figsize=(8,5))\n",
        "    sns.boxplot(x=df['room_type'], y=df['price'])\n",
        "    plt.ylim(0, df['price'].quantile(0.95))\n",
        "    plt.title(\"Price by Room Type\")\n",
        "    plt.show()\n",
        "\n",
        "# Neighbourhood vs average price\n",
        "if 'neighbourhood' in df.columns:\n",
        "    neigh_avg = df.groupby('neighbourhood')['price'].mean().sort_values(ascending=False).head(15)\n",
        "    plt.figure(figsize=(10,5))\n",
        "    sns.barplot(x=neigh_avg.values, y=neigh_avg.index)\n",
        "    plt.title(\"Top 15 Neighbourhoods by Avg Price\")\n",
        "    plt.show()\n",
        "\n",
        "# Scatter price vs number of reviews\n",
        "if {'number_of_reviews','price'}.issubset(df.columns):\n",
        "    plt.figure(figsize=(8,5))\n",
        "    sns.scatterplot(x='number_of_reviews', y='price', data=df, alpha=0.5)\n",
        "    plt.xlim(0, df['number_of_reviews'].quantile(0.95))\n",
        "    plt.ylim(0, df['price'].quantile(0.95))\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "zVzLTmf8WoFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) Feature engineering & cleaning\n",
        "\n",
        "df2 = df.copy()\n",
        "\n",
        "# Fill missing values\n",
        "for col in ['reviews_per_month','last_review']:\n",
        "    if col in df2.columns:\n",
        "        # For reviews_per_month, median; for last_review maybe convert to datetime\n",
        "        if col == 'reviews_per_month':\n",
        "            df2[col] = df2[col].fillna(df2[col].median())\n",
        "        else:\n",
        "            df2[col] = pd.to_datetime(df2[col], errors='coerce')\n",
        "            df2[col+'_year'] = df2[col].dt.year\n",
        "            df2[col+'_month'] = df2[col].dt.month\n",
        "            # then maybe drop the original\n",
        "            df2 = df2.drop(columns=[col])\n",
        "\n",
        "# Ensure 'accommodates' is present and clean before calculating 'price_per_person'\n",
        "if 'accommodates' in df2.columns:\n",
        "    df2 = df2.dropna(subset=['accommodates']) # Drop rows where 'accommodates' is missing\n",
        "    # Price per room if beds/accommodates are available\n",
        "    df2['price_per_person'] = df2['price'] / df2['accommodates'].replace({0:1})\n",
        "\n",
        "\n",
        "# Create distance to city center if lat/long present\n",
        "if {'latitude','longitude','price'}.issubset(df2.columns):\n",
        "    # Example: define city center as median lat/long of listings with valid price\n",
        "    center_lat = df2['latitude'].median()\n",
        "    center_lon = df2['longitude'].median()\n",
        "    df2['dist_to_center'] = np.sqrt((df2['latitude'] - center_lat)**2 + (df2['longitude'] - center_lon)**2)"
      ],
      "metadata": {
        "id": "4jVehR3PWta8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5) Clustering / segmentation\n",
        "features_for_cluster = []\n",
        "for c in ['price','number_of_reviews','availability_365','reviews_per_month','minimum_nights','dist_to_center']:\n",
        "    if c in df2.columns:\n",
        "        features_for_cluster.append(c)\n",
        "\n",
        "if len(features_for_cluster) >= 2:\n",
        "    Xc = df2[features_for_cluster].fillna(0)\n",
        "    scaler = StandardScaler()\n",
        "    Xc_scaled = scaler.fit_transform(Xc)\n",
        "    sse = []\n",
        "    # Limit the maximum number of clusters to the number of samples - 1\n",
        "    max_k = min(Xc_scaled.shape[0], 7) # Use min with 7 or other reasonable upper bound\n",
        "    for k in range(2, max_k):\n",
        "        km = KMeans(n_clusters=k, random_state=42, n_init=10) # Added n_init for newer sklearn versions\n",
        "        km.fit(Xc_scaled)\n",
        "        sse.append(km.inertia_)\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.plot(range(2, max_k), sse, '-o')\n",
        "    plt.title(\"Elbow Method for K\")\n",
        "    plt.xlabel(\"k\")\n",
        "    plt.ylabel(\"SSE\")\n",
        "    plt.show()\n",
        "\n",
        "    # example choose k=3 (ensure k is less than number of samples)\n",
        "    chosen_k = min(3, Xc_scaled.shape[0] -1) # Ensure chosen_k is valid\n",
        "    if chosen_k >= 2: # Check if clustering is still possible\n",
        "        km = KMeans(n_clusters=chosen_k, random_state=42, n_init=10) # Added n_init\n",
        "        df2['cluster'] = km.fit_predict(Xc_scaled)\n",
        "        # visualize clusters\n",
        "        if len(features_for_cluster) >= 2:\n",
        "            plt.figure(figsize=(8,5))\n",
        "            # Use the scaled features for plotting as they were used for clustering\n",
        "            sns.scatterplot(x=Xc_scaled[:,0], y=Xc_scaled[:,1], hue=df2['cluster'], palette='Set1')\n",
        "            plt.title(f\"Clusters in first two clustering features (k={chosen_k})\")\n",
        "            plt.show()\n",
        "    else:\n",
        "        print(\"Cannot perform clustering with less than 2 samples after feature selection.\")"
      ],
      "metadata": {
        "id": "dRUWsN2wWzVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6) Model for price prediction (regression)\n",
        "\n",
        "# Select useful features\n",
        "features = []\n",
        "# numeric candidates\n",
        "num_cands = ['minimum_nights','number_of_reviews','availability_365','dist_to_center','price_per_person']\n",
        "for c in num_cands:\n",
        "    if c in df2.columns:\n",
        "        features.append(c)\n",
        "# categorical candidates\n",
        "cat_cands = ['room_type','neighbourhood','neighbourhood_group','property_type']\n",
        "for c in cat_cands:\n",
        "    if c in df2.columns:\n",
        "        features.append(c)\n",
        "\n",
        "# Drop rows without price or feature nulls\n",
        "df_model = df2.dropna(subset=features + ['price'])\n",
        "print(\"Model data shape:\", df_model.shape)\n",
        "\n",
        "X = df_model[features]\n",
        "y = df_model['price']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Preprocessing: numeric scaling + categorical encoding\n",
        "num_features = [c for c in features if X[c].dtype in [np.int64, np.float64]]\n",
        "cat_features = [c for c in features if c not in num_features]\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', StandardScaler(), num_features),\n",
        "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features)\n",
        "])\n",
        "\n",
        "# RandomForest baseline\n",
        "rf = Pipeline([\n",
        "    ('pre', preprocessor),\n",
        "    ('model', RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1))\n",
        "])\n",
        "\n",
        "rf.fit(X_train, y_train)\n",
        "pred_rf = rf.predict(X_test)\n",
        "print(\"RF MAE:\", mean_absolute_error(y_test, pred_rf))\n",
        "print(\"RF RMSE:\", np.sqrt(mean_squared_error(y_test, pred_rf)))\n",
        "print(\"RF R2:\", r2_score(y_test, pred_rf))"
      ],
      "metadata": {
        "id": "NYKAXSq4XE0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7) XGBoost model & comparison\n",
        "\n",
        "# Select useful features (re-selecting to ensure consistency with potential changes in previous cells)\n",
        "features = []\n",
        "# numeric candidates\n",
        "num_cands = ['minimum_nights','number_of_reviews','availability_365','dist_to_center','price_per_person']\n",
        "for c in num_cands:\n",
        "    if c in df2.columns:\n",
        "        features.append(c)\n",
        "# categorical candidates\n",
        "cat_cands = ['room_type','neighbourhood','neighbourhood_group','property_type']\n",
        "for c in cat_cands:\n",
        "    if c in df2.columns:\n",
        "        features.append(c)\n",
        "\n",
        "# Drop rows with any missing values in the selected features AND price\n",
        "df_model = df2.dropna(subset=features + ['price'])\n",
        "\n",
        "X = df_model[features]\n",
        "y = df_model['price']\n",
        "\n",
        "# Ensure there's enough data after dropping NaNs\n",
        "if X.shape[0] < 2:\n",
        "    print(\"Not enough data after dropping missing values to perform train-test split.\")\n",
        "else:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Preprocessing: numeric scaling + categorical encoding (re-defining preprocessor as well)\n",
        "    num_features = [c for c in features if X[c].dtype in [np.int64, np.float64]]\n",
        "    cat_features = [c for c in features if c not in num_features]\n",
        "\n",
        "    preprocessor = ColumnTransformer([\n",
        "        ('num', StandardScaler(), num_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features)\n",
        "    ])\n",
        "\n",
        "    xgb_pipe = Pipeline([\n",
        "        ('pre', preprocessor),\n",
        "        ('model', xgb.XGBRegressor(n_estimators=200, learning_rate=0.1, random_state=42, n_jobs=1, verbosity=0))\n",
        "    ])\n",
        "\n",
        "    xgb_pipe.fit(X_train, y_train)\n",
        "    pred_xgb = xgb_pipe.predict(X_test)\n",
        "    print(\"XGB MAE:\", mean_absolute_error(y_test, pred_xgb))\n",
        "    print(\"XGB RMSE:\", np.sqrt(mean_squared_error(y_test, pred_xgb)))\n",
        "    print(\"XGB R2:\", r2_score(y_test, pred_xgb))"
      ],
      "metadata": {
        "id": "Jn3v4sUCX4PS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8) Plot actual vs predicted\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(y_test, pred_xgb, alpha=0.5)\n",
        "plt.plot([0, max(y_test.max(), pred_xgb.max())], [0, max(y_test.max(), pred_xgb.max())], 'r--')\n",
        "plt.xlabel(\"Actual Price\")\n",
        "plt.ylabel(\"Predicted Price\")\n",
        "plt.title(\"Actual vs Predicted Price (XGBoost)\")\n",
        "plt.ylim(0, y_test.quantile(0.95))\n",
        "plt.xlim(0, y_test.quantile(0.95))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "AwMvIpMuYgZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9) Feature importance from XGB\n",
        "\n",
        "# Extract feature names after encoding\n",
        "preprocessor.fit(X_train)\n",
        "num_names = num_features\n",
        "cat_names = []\n",
        "if len(cat_features) > 0:\n",
        "    ohe = preprocessor.named_transformers_['cat']\n",
        "    cat_names = list(ohe.get_feature_names_out(cat_features))\n",
        "\n",
        "all_feat_names = num_names + cat_names\n",
        "\n",
        "fi = pd.Series(xgb_pipe.named_steps['model'].feature_importances_, index=all_feat_names).sort_values(ascending=False).head(20)\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.barplot(x=fi.values, y=fi.index)\n",
        "plt.title(\"Top Features Importance (XGB)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UQi2Uw2MYk67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10) Save model for reuse\n",
        "import joblib\n",
        "joblib.dump(xgb_pipe, \"airbnb_price_model.joblib\")\n",
        "print(\"Saved XGB price model.\")\n",
        "files.download(\"airbnb_price_model.joblib\")\n"
      ],
      "metadata": {
        "id": "aDY7Doz3ZR-G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}